<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>huggingface下载工具git-lfs的使用笔记</title>
      <link href="/2024/09/19/huggingface%E4%B8%8B%E8%BD%BD%E5%B7%A5%E5%85%B7git-lfs%E7%9A%84%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/"/>
      <url>/2024/09/19/huggingface%E4%B8%8B%E8%BD%BD%E5%B7%A5%E5%85%B7git-lfs%E7%9A%84%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="一、Git-LFS的使用"><a href="#一、Git-LFS的使用" class="headerlink" title="一、Git LFS的使用"></a>一、Git LFS的使用</h2><p>Git LFS:（Large File Storage，解决git大文件存储问题）把音乐、图片、视频等指定的任意文件存在 Git 仓库之外，而在 Git 仓库中用一个占用空间 1KB 不到的文本指针来代替文件的存在,通过把大文件存储在 Git 仓库之外，可以减小 Git 仓库本身的体积，使克隆 Git 仓库的速度加快，也使得 Git 不会因为仓库中充满大文件而损失性能。</p><h2 id="二、安装"><a href="#二、安装" class="headerlink" title="二、安装"></a>二、安装</h2><p>（1）linux：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash</span><br><span class="line">sudo apt-get install git-lfs</span><br><span class="line">git lfs install</span><br></pre></td></tr></table></figure><p>（2）windows：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git lfs install</span><br></pre></td></tr></table></figure><h2 id="三、下载全部文件haggingface"><a href="#三、下载全部文件haggingface" class="headerlink" title="三、下载全部文件haggingface"></a>三、下载全部文件haggingface</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git lfs install</span><br><span class="line">git lfs clone https://huggingface.co/bigscience/bloom-7b1</span><br></pre></td></tr></table></figure><h2 id="四、下载中断、继续下载命令"><a href="#四、下载中断、继续下载命令" class="headerlink" title="四、下载中断、继续下载命令"></a>四、下载中断、继续下载命令</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git lfs fetch</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Conda环境打包笔记</title>
      <link href="/2024/09/19/Conda%E7%8E%AF%E5%A2%83%E6%89%93%E5%8C%85%E7%AC%94%E8%AE%B0/"/>
      <url>/2024/09/19/Conda%E7%8E%AF%E5%A2%83%E6%89%93%E5%8C%85%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h2><p>有时候自己的电脑上部署好的虚拟环境或者conda想要发给别人（节省部署时间），经常在想能不能有一种迁移环境的方法，可以迅速跑起项目。于是我就记录一下conda的打包和解包命令，方便以后查阅，提高工作效率！</p><h2 id="二、安装conda-pack"><a href="#二、安装conda-pack" class="headerlink" title="二、安装conda-pack"></a>二、安装conda-pack</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c conda-forge conda-pack</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install conda-pack</span><br></pre></td></tr></table></figure><h2 id="三、打包环境"><a href="#三、打包环境" class="headerlink" title="三、打包环境"></a>三、打包环境</h2><p>使用conda-pack命令打包为压缩文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda pack -n EnvName -o EnvName.tar.gz</span><br></pre></td></tr></table></figure><h2 id="四、传输压缩包"><a href="#四、传输压缩包" class="headerlink" title="四、传输压缩包"></a>四、传输压缩包</h2><p>自己找方法将压缩包传到其他地方，scp、rsync等都可以。</p><h2 id="五、解压包（另一台机子）"><a href="#五、解压包（另一台机子）" class="headerlink" title="五、解压包（另一台机子）"></a>五、解压包（另一台机子）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p ~/EnvName</span><br><span class="line">tar -xzf EnvName.tar.gz -C ~/EnvName</span><br></pre></td></tr></table></figure><h2 id="六、修复与激活"><a href="#六、修复与激活" class="headerlink" title="六、修复与激活"></a>六、修复与激活</h2><p>解压后要更改环境中的路径：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/EnvName/bin/conda-unpack</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/EnvName/bin/activate</span><br></pre></td></tr></table></figure><h2 id="七、添加到conda默认环境目录"><a href="#七、添加到conda默认环境目录" class="headerlink" title="七、添加到conda默认环境目录"></a>七、添加到conda默认环境目录</h2><p>可以创建一个软链接或移动环境目录(推荐)到 Conda 默认的环境目录中 ：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">软连接</span></span><br><span class="line">ln -s ~/StyleAvatar ~/miniconda3/envs/StyleAvatar</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">推荐</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">移动，这样conda <span class="built_in">env</span> list就可以看到了</span></span><br><span class="line">mv StyleAvatar/ ./miniconda3/envs/</span><br></pre></td></tr></table></figure><h2 id="八、例子"><a href="#八、例子" class="headerlink" title="八、例子"></a>八、例子</h2><p>自己的机子：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">安装</span></span><br><span class="line">pip install conda-pack</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">打包环境</span></span><br><span class="line">conda install -c conda-forge conda-pack</span><br><span class="line">conda pack -n StyleAvatar -o StyleAvatar.tar.gz</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">传输目标(scp)</span></span><br><span class="line">scp ./StyleAvatar.tar.gz 用户名@IP:/mnt/inais/data3/syp/</span><br></pre></td></tr></table></figure><p>目标机子：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">解压压缩包</span></span><br><span class="line">mkdir -p ~/StyleAvatar</span><br><span class="line">tar -xzf StyleAvatar.tar.gz -C ~/StyleAvatar</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修复环境路径</span></span><br><span class="line">~/StyleAvatar/bin/conda-unpack</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">激活环境</span></span><br><span class="line">source ~/StyleAvatar/bin/activate</span><br><span class="line"><span class="meta prompt_"> </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果conda识别不了，注意tar -xzf StyleAvatar.tar.gz -C ~/StyleAvatar这里</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可以创建一个软链接或移动环境目录到 Conda 默认的环境目录中</span></span><br><span class="line">cd ~/StyleAvatar</span><br><span class="line">mv StyleAvatar/ ./miniconda3/envs/</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>21天学通C++</title>
      <link href="/2024/08/11/21%E5%A4%A9%E5%AD%A6%E9%80%9AC++/"/>
      <url>/2024/08/11/21%E5%A4%A9%E5%AD%A6%E9%80%9AC++/</url>
      
        <content type="html"><![CDATA[<h2 id="一、绪论-第1天"><a href="#一、绪论-第1天" class="headerlink" title="一、绪论(第1天)"></a>一、绪论(第1天)</h2><h2 id="二、C-程序的组成部分-第1天"><a href="#二、C-程序的组成部分-第1天" class="headerlink" title="二、C++程序的组成部分(第1天)"></a>二、C++程序的组成部分(第1天)</h2><h2 id="三、使用变量和常量-第1天"><a href="#三、使用变量和常量-第1天" class="headerlink" title="三、使用变量和常量(第1天)"></a>三、使用变量和常量(第1天)</h2><h2 id="四、管理数组和字符串-第1天"><a href="#四、管理数组和字符串-第1天" class="headerlink" title="四、管理数组和字符串(第1天)"></a>四、管理数组和字符串(第1天)</h2><h2 id="五、使用表达式、语句和运算符-第1天"><a href="#五、使用表达式、语句和运算符-第1天" class="headerlink" title="五、使用表达式、语句和运算符(第1天)"></a>五、使用表达式、语句和运算符(第1天)</h2><h2 id="六、控制程序流程-第2天"><a href="#六、控制程序流程-第2天" class="headerlink" title="六、控制程序流程(第2天)"></a>六、控制程序流程(第2天)</h2><h2 id="七、使用函数组织代码-第2天"><a href="#七、使用函数组织代码-第2天" class="headerlink" title="七、使用函数组织代码(第2天)"></a>七、使用函数组织代码(第2天)</h2><h2 id="八、阐述指针和引用-第2天"><a href="#八、阐述指针和引用-第2天" class="headerlink" title="八、阐述指针和引用(第2天)"></a>八、阐述指针和引用(第2天)</h2><h2 id="九、类和对象-第2天"><a href="#九、类和对象-第2天" class="headerlink" title="九、类和对象(第2天)"></a>九、类和对象(第2天)</h2><h2 id="十、实现继承-第3天"><a href="#十、实现继承-第3天" class="headerlink" title="十、实现继承(第3天)"></a>十、实现继承(第3天)</h2><h2 id="十一、多态-第3天"><a href="#十一、多态-第3天" class="headerlink" title="十一、多态(第3天)"></a>十一、多态(第3天)</h2><h2 id="十二、运算符类型与运算符重载-第3天"><a href="#十二、运算符类型与运算符重载-第3天" class="headerlink" title="十二、运算符类型与运算符重载(第3天)"></a>十二、运算符类型与运算符重载(第3天)</h2><h2 id="十三、类型转换运算符-第3天"><a href="#十三、类型转换运算符-第3天" class="headerlink" title="十三、类型转换运算符(第3天)"></a>十三、类型转换运算符(第3天)</h2><h2 id="十四、宏和模板简介-第4天"><a href="#十四、宏和模板简介-第4天" class="headerlink" title="十四、宏和模板简介(第4天)"></a>十四、宏和模板简介(第4天)</h2><h2 id="十五、标准模板库简介-第4天"><a href="#十五、标准模板库简介-第4天" class="headerlink" title="十五、标准模板库简介(第4天)"></a>十五、标准模板库简介(第4天)</h2><h2 id="十六、STL-string类-第4天"><a href="#十六、STL-string类-第4天" class="headerlink" title="十六、STL string类(第4天)"></a>十六、STL string类(第4天)</h2><h2 id="十七、STL-动态数组类-第4天"><a href="#十七、STL-动态数组类-第4天" class="headerlink" title="十七、STL 动态数组类(第4天)"></a>十七、STL 动态数组类(第4天)</h2><h2 id="十八、STL-list和forward-list-第5天"><a href="#十八、STL-list和forward-list-第5天" class="headerlink" title="十八、STL list和forward_list(第5天)"></a>十八、STL list和forward_list(第5天)</h2><h2 id="十九、STL-集合类-第5天"><a href="#十九、STL-集合类-第5天" class="headerlink" title="十九、STL 集合类(第5天)"></a>十九、STL 集合类(第5天)</h2><h2 id="二十、STL-映射类-第5天"><a href="#二十、STL-映射类-第5天" class="headerlink" title="二十、STL 映射类(第5天)"></a>二十、STL 映射类(第5天)</h2><h2 id="二十一、理解函数对象-第5天"><a href="#二十一、理解函数对象-第5天" class="headerlink" title="二十一、理解函数对象(第5天)"></a>二十一、理解函数对象(第5天)</h2><h2 id="二十二、lambda-表达式-第6天"><a href="#二十二、lambda-表达式-第6天" class="headerlink" title="二十二、lambda 表达式(第6天)"></a>二十二、lambda 表达式(第6天)</h2><h2 id="二十三、STL算法-第6天"><a href="#二十三、STL算法-第6天" class="headerlink" title="二十三、STL算法(第6天)"></a>二十三、STL算法(第6天)</h2><h2 id="二十四、自适应容器：栈和队列-第6天"><a href="#二十四、自适应容器：栈和队列-第6天" class="headerlink" title="二十四、自适应容器：栈和队列(第6天)"></a>二十四、自适应容器：栈和队列(第6天)</h2><h2 id="二十五、使用STL位标志-第7天"><a href="#二十五、使用STL位标志-第7天" class="headerlink" title="二十五、使用STL位标志(第7天)"></a>二十五、使用STL位标志(第7天)</h2><h2 id="二十六、理解智能指针-第7天"><a href="#二十六、理解智能指针-第7天" class="headerlink" title="二十六、理解智能指针(第7天)"></a>二十六、理解智能指针(第7天)</h2><h2 id="二十七、使用流进行输入和输出-第7天"><a href="#二十七、使用流进行输入和输出-第7天" class="headerlink" title="二十七、使用流进行输入和输出(第7天)"></a>二十七、使用流进行输入和输出(第7天)</h2><h2 id="二十八、异常处理-第8天"><a href="#二十八、异常处理-第8天" class="headerlink" title="二十八、异常处理(第8天)"></a>二十八、异常处理(第8天)</h2><h2 id="二十九、继续前行-第8天"><a href="#二十九、继续前行-第8天" class="headerlink" title="二十九、继续前行(第8天)"></a>二十九、继续前行(第8天)</h2>]]></content>
      
      
      <categories>
          
          <category> C++ </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>ComfyUI的学习笔记</title>
      <link href="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>推荐教程：</p><p>（1）<a href="https://www.bilibili.com/video/BV1sW42197fN?p=1&vd_source=0c4d2c8d0a9190a4bb7587a15f6341f2">https://www.bilibili.com/video/BV1sW42197fN?p=1&amp;vd_source=0c4d2c8d0a9190a4bb7587a15f6341f2</a></p><p>（2）<a href="https://www.bilibili.com/video/BV13b4y1G7s9/?spm_id_from=333.788&vd_source=0c4d2c8d0a9190a4bb7587a15f6341f2">https://www.bilibili.com/video/BV13b4y1G7s9/?spm_id_from=333.788&amp;vd_source=0c4d2c8d0a9190a4bb7587a15f6341f2</a></p><p>（3）<a href="https://www.bilibili.com/video/BV1Bi421e73X/?p=1&vd_source=0c4d2c8d0a9190a4bb7587a15f6341f2">https://www.bilibili.com/video/BV1Bi421e73X/?p=1&amp;vd_source=0c4d2c8d0a9190a4bb7587a15f6341f2</a></p><h2 id="一、原理"><a href="#一、原理" class="headerlink" title="一、原理"></a>一、原理</h2><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.png" alt="1"></p><p>整个大模型Checkpoint包括VAE、CLIP、Latent、U-net这几个部分组件。</p><p>（1）大模型（ControlNet、Lora等）包括以下：</p><p>​.ckpt：基于TensorFlow框架；</p><p>​.h5：基于Keras框架；</p><p>​.pt&#x2F;.pth：基于PyTorch框架；</p><p>​.onnx：开发式标准格式。</p><p>（2）Stable Diffusion架构分类：</p><p>​SD1.x：如SD1.x lighting</p><p>​SDXL：如SDXL Hyper</p><p>​SD3、Flux</p><h2 id="二、文生图"><a href="#二、文生图" class="headerlink" title="二、文生图"></a>二、文生图</h2><p>（1）工作流介绍</p><p>1）checkpoint加载器：以majic写实模型为例子</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2.png" alt="2"></p><p>2）CLIP文本编码器：正向、负向提示词</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/3.png" alt="3"></p><p>3）K采样器：去噪过程</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/4.png" alt="4"></p><p>4）空Latent：存放空间</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.png" alt="5"></p><p>5）VAE解码器：</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/6.png" alt="6"></p><p>最后是整体的工作流：</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/7.png" alt="7"></p><p>（2）生成后的图片</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.png" alt="8"></p><h2 id="三、VAE、Lora和ControlNet模块"><a href="#三、VAE、Lora和ControlNet模块" class="headerlink" title="三、VAE、Lora和ControlNet模块"></a>三、VAE、Lora和ControlNet模块</h2><p>（1）VAE</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/9.png" alt="9"></p><p>（2）Lora</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/10.png" alt="10"></p><p>（3）ControlNet</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/11.png" alt="11"></p><h2 id="四、图生图"><a href="#四、图生图" class="headerlink" title="四、图生图"></a>四、图生图</h2><p>（1）图生图：</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/12.png" alt="12"></p><p>（2）VAE内补编码器：</p><p>VAE编码器：</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/13.png" alt="13"></p><p>VAE内补编码器：</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/14.png" alt="14"></p><p>图像对比：</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/15.jpg" alt="15"></p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/16.jpg" alt="16"></p><p>（3）设置Latent噪波遮罩；</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/17.png" alt="17"></p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/18.png" alt="18"></p><p>图像为：</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/19.jpg" alt="19"></p><h2 id="五、扩展图片"><a href="#五、扩展图片" class="headerlink" title="五、扩展图片"></a>五、扩展图片</h2><p>常见两种放大方法（latent按系数和图像通过模型放大）：</p><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/20.png" alt="20"></p><h2 id="六、图像裁剪（缩放）"><a href="#六、图像裁剪（缩放）" class="headerlink" title="六、图像裁剪（缩放）"></a>六、图像裁剪（缩放）</h2><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/21.png" alt="21"></p><h2 id="七、反推图片提示词"><a href="#七、反推图片提示词" class="headerlink" title="七、反推图片提示词"></a>七、反推图片提示词</h2><p><img src="/2024/08/11/ComfyUI%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/22.png" alt="22"></p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>GFPGAN:用于真实世界面部修复的实用算法</title>
      <link href="/2024/07/25/GFPGAN-%E7%94%A8%E4%BA%8E%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E9%9D%A2%E9%83%A8%E4%BF%AE%E5%A4%8D%E7%9A%84%E5%AE%9E%E7%94%A8%E7%AE%97%E6%B3%95/"/>
      <url>/2024/07/25/GFPGAN-%E7%94%A8%E4%BA%8E%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E9%9D%A2%E9%83%A8%E4%BF%AE%E5%A4%8D%E7%9A%84%E5%AE%9E%E7%94%A8%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id="一、GFPGAN"><a href="#一、GFPGAN" class="headerlink" title="一、GFPGAN"></a>一、GFPGAN</h2><h3 id="（1）介绍"><a href="#（1）介绍" class="headerlink" title="（1）介绍"></a>（1）介绍</h3><p>官网地址：<a href="https://github.com/TencentARC/GFPGAN/tree/master">TencentARC&#x2F;GFPGAN: GFPGAN aims at developing Practical Algorithms for Real-world Face Restoration. (github.com)</a></p><p>这个GFPGAN是一种图像修复的算法，可以把破旧模糊的图片还原成清晰可见的照片。</p><p>一点也不夸张，我试了一下，把一个64x64的照片变成256x256分辨率的清晰照片，非常高清。</p><p>这个算法是基于这个叫<a href="https://github.com/xinntao/Real-ESRGAN">Real-ESRGAN</a>的项目，所以都是一步步迭代上来的，挺了不起的！感兴趣的朋友可以去复现一下。这里面还有需要注意的两个项目包，前面的<code>real-rsrgan</code>和<code>gfpgan</code>都是基于下面两个基础上完成的：</p><p> <a href="https://github.com/xinntao/BasicSR">BasicSR</a>: An open-source image and video restoration toolbox<br><a href="https://github.com/xinntao/facexlib">facexlib</a>: A collection that provides useful face-relation functions</p><p>basicsr负责的是图像和视频修复，这个是最厉害的工具，而facexlib是提供面部关系一个函数库，提高修复效果。<br>论文：GFP-GAN: Towards Real-World Blind Face Restoration with Generative Facial Prior</p><h3 id="（2）安装环境"><a href="#（2）安装环境" class="headerlink" title="（2）安装环境"></a>（2）安装环境</h3><p>1）主要是python≥3.7、pytorch≥1.7、一块GPU显卡</p><p>2）下载命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/TencentARC/GFPGAN.git</span><br><span class="line">cd GFPGAN</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Install basicsr - https://github.com/xinntao/BasicSR</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">We use BasicSR <span class="keyword">for</span> both training and inference</span></span><br><span class="line">pip install basicsr</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Install facexlib - https://github.com/xinntao/facexlib</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">We use face detection and face restoration helper <span class="keyword">in</span> the facexlib package</span></span><br><span class="line">pip install facexlib</span><br><span class="line"></span><br><span class="line">pip install -r requirements.txt</span><br><span class="line">python setup.py develop</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">If you want to enhance the background (non-face) regions with Real-ESRGAN,</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">you also need to install the realesrgan package</span></span><br><span class="line">pip install realesrgan</span><br></pre></td></tr></table></figure><p>3）下载模型GFPGANv1.3（可选项，也可以是v1.2和v1）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models</span><br></pre></td></tr></table></figure><p>4）运行代码，run：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python inference_gfpgan.py -i inputs/whole_imgs -o results -v 1.3 -s 2</span><br></pre></td></tr></table></figure><p>命令的一些参数：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Usage: python inference_gfpgan.py -i inputs/whole_imgs -o results -v 1.3 -s 2 [options]...</span><br><span class="line"></span><br><span class="line">  -h                   show this help</span><br><span class="line">  -i input             Input image or folder. Default: inputs/whole_imgs</span><br><span class="line">  -o output            Output folder. Default: results</span><br><span class="line">  -v version           GFPGAN model version. Option: 1 | 1.2 | 1.3. Default: 1.3</span><br><span class="line">  -s upscale           The final upsampling scale of the image. Default: 2</span><br><span class="line">  -bg_upsampler        background upsampler. Default: realesrgan</span><br><span class="line">  -bg_tile             Tile size for background sampler, 0 for no tile during testing. Default: 400</span><br><span class="line">  -suffix              Suffix of the restored faces</span><br><span class="line">  -only_center_face    Only restore the center face</span><br><span class="line">  -aligned             Input are aligned faces</span><br><span class="line">  -ext                 Image extension. Options: auto | jpg | png, auto means using the same extension as inputs. Default: auto</span><br></pre></td></tr></table></figure><h2 id="二、项目结构和代码介绍"><a href="#二、项目结构和代码介绍" class="headerlink" title="二、项目结构和代码介绍"></a>二、项目结构和代码介绍</h2><h3 id="（1）代码地址"><a href="#（1）代码地址" class="headerlink" title="（1）代码地址"></a>（1）代码地址</h3><p><a href="https://github.com/Lucki-ly/GFPGAN_1">https://github.com/Lucki-ly/GFPGAN_1</a></p><h3 id="（2）项目结构"><a href="#（2）项目结构" class="headerlink" title="（2）项目结构"></a>（2）项目结构</h3><p><img src="/2024/07/25/GFPGAN-%E7%94%A8%E4%BA%8E%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E9%9D%A2%E9%83%A8%E4%BF%AE%E5%A4%8D%E7%9A%84%E5%AE%9E%E7%94%A8%E7%AE%97%E6%B3%95/1.png" alt="1"></p><p>如上图所示，项目的结构有这么多，解释如下：<br>1）experiments：存放pretrained_models，就是我们的模型（GFPGANv1.3.pth等）；</p><p>2）gfpgan：模型的目录；</p><p>3）inputs：输入文件的目录；</p><p>4）options：存放一些训练的yaml文件；</p><p>5）results：输出文件的目录；</p><p>6）tests：存放一些测试的文件，测试功能；</p><p>7）inference_gfpgan.py：项目接口的运行主文件，我们靠这个调用所有的功能；</p><p>8）requirements.txt：项目要求的安装文件；</p><p>9）setup.py：项目的启动文件，运行之前要python一下。</p><h3 id="（3）代码调整"><a href="#（3）代码调整" class="headerlink" title="（3）代码调整"></a>（3）代码调整</h3><p>我做了一个图像尺寸（分辨率）的控制，这样我们可以根据自己的需求去获得想要的大小。</p><p>前面的参数增加：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">&#x27;-d&#x27;</span>, <span class="string">&#x27;--desired_size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">512</span>, <span class="built_in">help</span>=<span class="string">&#x27;Desired size for the output images. Default: 256&#x27;</span>)</span><br></pre></td></tr></table></figure><p>restore部分修改：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># ------------------------ restore ------------------------</span></span><br><span class="line"><span class="keyword">for</span> img_path <span class="keyword">in</span> img_list:</span><br><span class="line">    <span class="comment"># read image</span></span><br><span class="line">    img_name = os.path.basename(img_path)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Processing <span class="subst">&#123;img_name&#125;</span> ...&#x27;</span>)</span><br><span class="line">    basename, ext = os.path.splitext(img_name)</span><br><span class="line">    input_img = cv2.imread(img_path, cv2.IMREAD_COLOR)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="comment"># Print the size of the input image</span></span><br><span class="line">    height, width, _ = input_img.shape</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Input image size: <span class="subst">&#123;width&#125;</span>x<span class="subst">&#123;height&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># restore faces and background if necessary</span></span><br><span class="line">    cropped_faces, restored_faces, restored_img = restorer.enhance(</span><br><span class="line">        input_img,</span><br><span class="line">        has_aligned=args.aligned,</span><br><span class="line">        only_center_face=args.only_center_face,</span><br><span class="line">        paste_back=<span class="literal">True</span>,</span><br><span class="line">        weight=args.weight)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print the size of the restored image</span></span><br><span class="line">    <span class="keyword">if</span> restored_img <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        height, width, _ = restored_img.shape</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Restored image size: <span class="subst">&#123;width&#125;</span>x<span class="subst">&#123;height&#125;</span>&#x27;</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># Resize the restored image to 256x256</span></span><br><span class="line">        restored_img = cv2.resize(restored_img, (args.desired_size, args.desired_size), interpolation=cv2.INTER_LINEAR)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># Print the size of the restored image after resizing</span></span><br><span class="line">        height, width, _ = restored_img.shape</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Restored image size after resizing: <span class="subst">&#123;width&#125;</span>x<span class="subst">&#123;height&#125;</span>&#x27;</span>)</span><br><span class="line">            </span><br><span class="line">    <span class="comment"># save faces</span></span><br><span class="line">    <span class="keyword">for</span> idx, (cropped_face, restored_face) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(cropped_faces, restored_faces)):</span><br><span class="line">        cropped_face = cv2.resize(cropped_face, (args.desired_size, args.desired_size), interpolation=cv2.INTER_LINEAR)</span><br><span class="line">        restored_face = cv2.resize(restored_face, (args.desired_size, args.desired_size), interpolation=cv2.INTER_LINEAR)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># save cropped face</span></span><br><span class="line">        save_crop_path = os.path.join(args.output, <span class="string">&#x27;cropped_faces&#x27;</span>, <span class="string">f&#x27;<span class="subst">&#123;basename&#125;</span>_<span class="subst">&#123;idx:02d&#125;</span>.jpg&#x27;</span>)</span><br><span class="line">        imwrite(cropped_face, save_crop_path)</span><br><span class="line">        <span class="comment"># save restored face</span></span><br><span class="line">        <span class="keyword">if</span> args.suffix <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            save_face_name = <span class="string">f&#x27;<span class="subst">&#123;basename&#125;</span>_<span class="subst">&#123;idx:02d&#125;</span>_<span class="subst">&#123;args.suffix&#125;</span>.jpg&#x27;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            save_face_name = <span class="string">f&#x27;<span class="subst">&#123;basename&#125;</span>_<span class="subst">&#123;idx:02d&#125;</span>.jpg&#x27;</span></span><br><span class="line">        save_restore_path = os.path.join(args.output, <span class="string">&#x27;restored_faces&#x27;</span>, save_face_name)</span><br><span class="line">        imwrite(restored_face, save_restore_path)</span><br><span class="line">        <span class="comment"># save comparison image</span></span><br><span class="line">        cmp_img = np.concatenate((cropped_face, restored_face), axis=<span class="number">1</span>)</span><br><span class="line">        imwrite(cmp_img, os.path.join(args.output, <span class="string">&#x27;cmp&#x27;</span>, <span class="string">f&#x27;<span class="subst">&#123;basename&#125;</span>_<span class="subst">&#123;idx:02d&#125;</span>.jpg&#x27;</span>))</span><br></pre></td></tr></table></figure><h2 id="三、效果展示"><a href="#三、效果展示" class="headerlink" title="三、效果展示"></a>三、效果展示</h2><p><img src="/2024/07/25/GFPGAN-%E7%94%A8%E4%BA%8E%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E9%9D%A2%E9%83%A8%E4%BF%AE%E5%A4%8D%E7%9A%84%E5%AE%9E%E7%94%A8%E7%AE%97%E6%B3%95/2.jpg" alt="2"></p><p><img src="/2024/07/25/GFPGAN-%E7%94%A8%E4%BA%8E%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E9%9D%A2%E9%83%A8%E4%BF%AE%E5%A4%8D%E7%9A%84%E5%AE%9E%E7%94%A8%E7%AE%97%E6%B3%95/3.jpg" alt="3"></p><p><img src="/2024/07/25/GFPGAN-%E7%94%A8%E4%BA%8E%E7%9C%9F%E5%AE%9E%E4%B8%96%E7%95%8C%E9%9D%A2%E9%83%A8%E4%BF%AE%E5%A4%8D%E7%9A%84%E5%AE%9E%E7%94%A8%E7%AE%97%E6%B3%95/4.jpg" alt="4"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>基于多实例学习和yolov10实现水下目标检测（RUOD）</title>
      <link href="/2024/07/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0%E5%92%8Cyolov10%E5%AE%9E%E7%8E%B0%E6%B0%B4%E4%B8%8B%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88RUOD%EF%BC%89/"/>
      <url>/2024/07/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0%E5%92%8Cyolov10%E5%AE%9E%E7%8E%B0%E6%B0%B4%E4%B8%8B%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88RUOD%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h2><p>清华大学发了一篇《<a href="https://arxiv.org/abs/2405.14458">YOLOv10: Real-Time End-to-End Object Detection</a>》论文，提升了计算机视觉模型的性能，而且响应更快。</p><p>于是我结合了百度飞桨paddle开源的水下目标检测Ruod数据集，然后将多实例学习注意力机制结合到yolov10，让它能学习更快，效率更高。接下来是我做的工作：</p><h2 id="二、准备工作"><a href="#二、准备工作" class="headerlink" title="二、准备工作"></a>二、准备工作</h2><h3 id="（1）运行环境"><a href="#（1）运行环境" class="headerlink" title="（1）运行环境"></a>（1）运行环境</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python≥3.9</span><br><span class="line">anaconda</span><br><span class="line">GeForce Nvidia 1080ti</span><br><span class="line">Windows</span><br></pre></td></tr></table></figure><h3 id="（2）YOLOv10安装"><a href="#（2）YOLOv10安装" class="headerlink" title="（2）YOLOv10安装"></a>（2）YOLOv10安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">conda create -n yolo10 python=3.9</span><br><span class="line">conda activate yolo10</span><br><span class="line">git https://github.com/THU-MIG/yolov10.git</span><br><span class="line">cd yolov10-main</span><br><span class="line">pip install -r requirements.txt</span><br><span class="line">pip install -e .</span><br></pre></td></tr></table></figure><p>遇到报错：ERROR: No matching distribution found for xxxx.</p><p>解决方法，离线安装：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -e .  --no-build-isolation --no-index --find-links=./</span><br></pre></td></tr></table></figure><p>然后根据缺少的包<code>pip install</code>。</p><h3 id="（3）RUOD数据集"><a href="#（3）RUOD数据集" class="headerlink" title="（3）RUOD数据集"></a>（3）RUOD数据集</h3><p>1）下载：<a href="https://aistudio.baidu.com/datasetdetail/216919">水下目标检测Ruod数据集_数据集-飞桨AI Studio星河社区 </a>，一共有holothurian，echinus，scallop，starfish，fish，corals，diver，cuttlefish，turtle，jellyfish10个常见类别；</p><p>2）数据处理：</p><p>数据集要处理从COCO格式，所以我们要做这一步，在<code>yolov10-main</code>目录下新建一个py文件，填入代码并python一下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_folders</span>(<span class="params">path=<span class="string">&#x27;./coco/&#x27;</span></span>):</span><br><span class="line">    <span class="comment"># Create folders</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(path):</span><br><span class="line">        shutil.rmtree(path)  <span class="comment"># delete output folder</span></span><br><span class="line">    os.makedirs(path)  <span class="comment"># make new output folder</span></span><br><span class="line">    os.makedirs(path + os.sep + <span class="string">&#x27;labels&#x27;</span>)  <span class="comment"># make new labels folder</span></span><br><span class="line">    os.makedirs(path + os.sep + <span class="string">&#x27;images&#x27;</span>)  <span class="comment"># make new images folder</span></span><br><span class="line">    <span class="keyword">return</span> path</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_coco_json</span>(<span class="params">json_dir=<span class="string">&#x27;H:/xiangmu/2/RUOD/RUOD_ANN/&#x27;</span></span>):</span><br><span class="line">    jsons = glob.glob(json_dir + <span class="string">&#x27;*.json&#x27;</span>)  <span class="comment"># Import json</span></span><br><span class="line">    <span class="keyword">for</span> json_file <span class="keyword">in</span> <span class="built_in">sorted</span>(jsons):</span><br><span class="line">        fn = <span class="string">&#x27;coco/labels/%s/&#x27;</span> % Path(json_file).stem.replace(<span class="string">&#x27;instances_&#x27;</span>, <span class="string">&#x27;&#x27;</span>)  <span class="comment"># folder name</span></span><br><span class="line">        fn_images = <span class="string">&#x27;coco/images/%s/&#x27;</span> % Path(json_file).stem.replace(<span class="string">&#x27;instances_&#x27;</span>, <span class="string">&#x27;&#x27;</span>)  <span class="comment"># folder name</span></span><br><span class="line">        os.makedirs(fn, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        os.makedirs(fn_images, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(json_file) <span class="keyword">as</span> f:</span><br><span class="line">            data = json.load(f)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(fn)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Create image dict</span></span><br><span class="line">        images = &#123;<span class="string">&#x27;%g&#x27;</span> % x[<span class="string">&#x27;id&#x27;</span>]: x <span class="keyword">for</span> x <span class="keyword">in</span> data[<span class="string">&#x27;images&#x27;</span>]&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Write labels file</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> tqdm(data[<span class="string">&#x27;annotations&#x27;</span>], desc=<span class="string">&#x27;Annotations %s&#x27;</span> % json_file):</span><br><span class="line">            <span class="keyword">if</span> x[<span class="string">&#x27;iscrowd&#x27;</span>]:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            img = images[<span class="string">&#x27;%g&#x27;</span> % x[<span class="string">&#x27;image_id&#x27;</span>]]</span><br><span class="line">            h, w, f = img[<span class="string">&#x27;height&#x27;</span>], img[<span class="string">&#x27;width&#x27;</span>], img[<span class="string">&#x27;file_name&#x27;</span>]</span><br><span class="line">            file_path = <span class="string">&#x27;./RUOD/RUOD_pic/&#x27;</span> + fn.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">2</span>] + <span class="string">&quot;/&quot;</span> + f</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># The Labelbox bounding box format is [top left x, top left y, width, height]</span></span><br><span class="line">            box = np.array(x[<span class="string">&#x27;bbox&#x27;</span>], dtype=np.float64)</span><br><span class="line">            box[:<span class="number">2</span>] += box[<span class="number">2</span>:] / <span class="number">2</span>  <span class="comment"># xy top-left corner to center</span></span><br><span class="line">            box[[<span class="number">0</span>, <span class="number">2</span>]] /= w  <span class="comment"># normalize x</span></span><br><span class="line">            box[[<span class="number">1</span>, <span class="number">3</span>]] /= h  <span class="comment"># normalize y</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> (box[<span class="number">2</span>] &gt; <span class="number">0.</span>) <span class="keyword">and</span> (box[<span class="number">3</span>] &gt; <span class="number">0.</span>):  <span class="comment"># if w &gt; 0 and h &gt; 0</span></span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(fn + Path(f).stem + <span class="string">&#x27;.txt&#x27;</span>, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">                    file.write(<span class="string">&#x27;%g %.6f %.6f %.6f %.6f\n&#x27;</span> % (x[<span class="string">&#x27;category_id&#x27;</span>] - <span class="number">1</span>, *box))</span><br><span class="line">            </span><br><span class="line">            file_path_t = fn_images + f</span><br><span class="line">            <span class="built_in">print</span>(file_path, file_path_t)</span><br><span class="line">            shutil.copy(file_path, file_path_t)</span><br><span class="line"></span><br><span class="line">convert_coco_json()</span><br></pre></td></tr></table></figure><p>然后运行之后，在同级目录下新建一个叫<code>coco.yaml</code>的文件，输入内容：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">train:</span> <span class="string">./coco/images/train</span> <span class="comment"># train images</span></span><br><span class="line"><span class="attr">val:</span> <span class="string">./coco/images/test</span> <span class="comment"># val images</span></span><br><span class="line"><span class="attr">names:</span> [<span class="string">&#x27;holothurian&#x27;</span>, <span class="string">&#x27;echinus&#x27;</span>, <span class="string">&#x27;scallop&#x27;</span>, <span class="string">&#x27;starfish&#x27;</span>,<span class="string">&#x27;fish&#x27;</span>,<span class="string">&#x27;corals&#x27;</span>,<span class="string">&#x27;diver&#x27;</span>,<span class="string">&#x27;cuttlefish&#x27;</span>,<span class="string">&#x27;turtle&#x27;</span>,<span class="string">&#x27;jellyfish&#x27;</span>]</span><br></pre></td></tr></table></figure><p>项目结构如下：</p><p><img src="/2024/07/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0%E5%92%8Cyolov10%E5%AE%9E%E7%8E%B0%E6%B0%B4%E4%B8%8B%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88RUOD%EF%BC%89/1.png" alt="1"></p><p>3）可以开始训练模型了，同级目录下新建文件<code>main.py</code>，输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> ultralytics <span class="keyword">import</span> YOLOv10</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Attention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.M = <span class="number">500</span></span><br><span class="line">        <span class="variable language_">self</span>.L = <span class="number">128</span></span><br><span class="line">        <span class="variable language_">self</span>.ATTENTION_BRANCHES = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.feature_extractor_part1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">20</span>, <span class="number">50</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.feature_extractor_part2 = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">50</span> * <span class="number">4</span> * <span class="number">4</span>, <span class="variable language_">self</span>.M),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.attention = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="variable language_">self</span>.M, <span class="variable language_">self</span>.L), <span class="comment"># matrix V</span></span><br><span class="line">            nn.Tanh(),</span><br><span class="line">            nn.Linear(<span class="variable language_">self</span>.L, <span class="variable language_">self</span>.ATTENTION_BRANCHES) <span class="comment"># matrix w (or vector w if self.ATTENTION_BRANCHES==1)</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.classifier = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="variable language_">self</span>.M*<span class="variable language_">self</span>.ATTENTION_BRANCHES, <span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x.squeeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        H = <span class="variable language_">self</span>.feature_extractor_part1(x)</span><br><span class="line">        H = H.view(-<span class="number">1</span>, <span class="number">50</span> * <span class="number">4</span> * <span class="number">4</span>)</span><br><span class="line">        H = <span class="variable language_">self</span>.feature_extractor_part2(H)  <span class="comment"># KxM</span></span><br><span class="line"></span><br><span class="line">        A = <span class="variable language_">self</span>.attention(H)  <span class="comment"># KxATTENTION_BRANCHES</span></span><br><span class="line">        A = torch.transpose(A, <span class="number">1</span>, <span class="number">0</span>)  <span class="comment"># ATTENTION_BRANCHESxK</span></span><br><span class="line">        A = F.softmax(A, dim=<span class="number">1</span>)  <span class="comment"># softmax over K</span></span><br><span class="line"></span><br><span class="line">        Z = torch.mm(A, H)  <span class="comment"># ATTENTION_BRANCHESxM</span></span><br><span class="line"></span><br><span class="line">        Y_prob = <span class="variable language_">self</span>.classifier(Z)</span><br><span class="line">        Y_hat = torch.ge(Y_prob, <span class="number">0.5</span>).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Y_prob, Y_hat, A</span><br><span class="line"></span><br><span class="line">    <span class="comment"># AUXILIARY METHODS</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;def calculate_classification_error(self, X, Y):</span></span><br><span class="line"><span class="string">        Y = Y.float()</span></span><br><span class="line"><span class="string">        _, Y_hat, _ = self.forward(X)</span></span><br><span class="line"><span class="string">        error = 1. - Y_hat.eq(Y).cpu().float().mean().data.item()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        return error, Y_hat</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def calculate_objective(self, X, Y):</span></span><br><span class="line"><span class="string">        Y = Y.float()</span></span><br><span class="line"><span class="string">        Y_prob, _, A = self.forward(X)</span></span><br><span class="line"><span class="string">        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)</span></span><br><span class="line"><span class="string">        neg_log_likelihood = -1. * (Y * torch.log(Y_prob) + (1. - Y) * torch.log(1. - Y_prob))  # negative log bernoulli</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        return neg_log_likelihood, A&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GatedAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(GatedAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.M = <span class="number">500</span></span><br><span class="line">        <span class="variable language_">self</span>.L = <span class="number">128</span></span><br><span class="line">        <span class="variable language_">self</span>.ATTENTION_BRANCHES = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.feature_extractor_part1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">20</span>, <span class="number">50</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.feature_extractor_part2 = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">50</span> * <span class="number">4</span> * <span class="number">4</span>, <span class="variable language_">self</span>.M),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.attention_V = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="variable language_">self</span>.M, <span class="variable language_">self</span>.L), <span class="comment"># matrix V</span></span><br><span class="line">            nn.Tanh()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.attention_U = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="variable language_">self</span>.M, <span class="variable language_">self</span>.L), <span class="comment"># matrix U</span></span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.attention_w = nn.Linear(<span class="variable language_">self</span>.L, <span class="variable language_">self</span>.ATTENTION_BRANCHES) <span class="comment"># matrix w (or vector w if self.ATTENTION_BRANCHES==1)</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.classifier = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="variable language_">self</span>.M*<span class="variable language_">self</span>.ATTENTION_BRANCHES, <span class="number">1</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x.squeeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        H = <span class="variable language_">self</span>.feature_extractor_part1(x)</span><br><span class="line">        H = H.view(-<span class="number">1</span>, <span class="number">50</span> * <span class="number">4</span> * <span class="number">4</span>)</span><br><span class="line">        H = <span class="variable language_">self</span>.feature_extractor_part2(H)  <span class="comment"># KxM</span></span><br><span class="line"></span><br><span class="line">        A_V = <span class="variable language_">self</span>.attention_V(H)  <span class="comment"># KxL</span></span><br><span class="line">        A_U = <span class="variable language_">self</span>.attention_U(H)  <span class="comment"># KxL</span></span><br><span class="line">        A = <span class="variable language_">self</span>.attention_w(A_V * A_U) <span class="comment"># element wise multiplication # KxATTENTION_BRANCHES</span></span><br><span class="line">        A = torch.transpose(A, <span class="number">1</span>, <span class="number">0</span>)  <span class="comment"># ATTENTION_BRANCHESxK</span></span><br><span class="line">        A = F.softmax(A, dim=<span class="number">1</span>)  <span class="comment"># softmax over K</span></span><br><span class="line"></span><br><span class="line">        Z = torch.mm(A, H)  <span class="comment"># ATTENTION_BRANCHESxM</span></span><br><span class="line"></span><br><span class="line">        Y_prob = <span class="variable language_">self</span>.classifier(Z)</span><br><span class="line">        Y_hat = torch.ge(Y_prob, <span class="number">0.5</span>).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Y_prob, Y_hat, A</span><br><span class="line"></span><br><span class="line">    <span class="comment"># AUXILIARY METHODS</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;def calculate_classification_error(self, X, Y):</span></span><br><span class="line"><span class="string">        Y = Y.float()</span></span><br><span class="line"><span class="string">        _, Y_hat, _ = self.forward(X)</span></span><br><span class="line"><span class="string">        error = 1. - Y_hat.eq(Y).cpu().float().mean().item()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        return error, Y_hat</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def calculate_objective(self, X, Y):</span></span><br><span class="line"><span class="string">        Y = Y.float()</span></span><br><span class="line"><span class="string">        Y_prob, _, A = self.forward(X)</span></span><br><span class="line"><span class="string">        Y_prob = torch.clamp(Y_prob, min=1e-5, max=1. - 1e-5)</span></span><br><span class="line"><span class="string">        neg_log_likelihood = -1. * (Y * torch.log(Y_prob) + (1. - Y) * torch.log(1. - Y_prob))  # negative log bernoulli</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        return neg_log_likelihood, A&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MIL_YOLOv10</span>(<span class="title class_ inherited__">YOLOv10</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_cfg, attention_type=<span class="string">&#x27;attention&#x27;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(MIL_YOLOv10, <span class="variable language_">self</span>).__init__(model_cfg)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 加载预训练权重</span></span><br><span class="line">        <span class="variable language_">self</span>.load(<span class="string">&#x27;yolov10n.pt&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 选择注意力机制</span></span><br><span class="line">        <span class="keyword">if</span> attention_type == <span class="string">&#x27;attention&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.attention_module = Attention()</span><br><span class="line">        <span class="keyword">elif</span> attention_type == <span class="string">&#x27;gated_attention&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.attention_module = GatedAttention()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;Unknown attention type&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 获取 YOLOv10 的特征图</span></span><br><span class="line">        features = <span class="built_in">super</span>().forward(x)  <span class="comment"># 使用 YOLOv10 的特征提取</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将特征图展平并通过 MIL 模块</span></span><br><span class="line">        features = features.view(features.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 通过注意力机制处理特征</span></span><br><span class="line">        attention_weights, _, _ = <span class="variable language_">self</span>.attention_module(features)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> attention_weights</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 创建 MIL-YOLOv10 模型</span></span><br><span class="line">    model_cfg = <span class="string">&quot;H:/xiangmu/2/yolov10/ultralytics/cfg/models/v10/yolov10n.yaml&quot;</span></span><br><span class="line">    model = MIL_YOLOv10(model_cfg, attention_type=<span class="string">&#x27;attention&#x27;</span>)  <span class="comment"># 选择 &#x27;attention&#x27; 或 &#x27;gated_attention&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练模型</span></span><br><span class="line">    <span class="comment"># 由于 `YOLOv10` 可能会提供高层次的训练接口，具体训练过程请参考 YOLOv10 文档</span></span><br><span class="line">    <span class="comment"># 此处假设 YOLOv10 的 `train` 方法可以直接调用</span></span><br><span class="line">    results = model.train(</span><br><span class="line">        data=<span class="string">&quot;coco.yaml&quot;</span>,</span><br><span class="line">        patience=<span class="number">0</span>,</span><br><span class="line">        epochs=<span class="number">50</span>,</span><br><span class="line">        device=<span class="string">&#x27;0&#x27;</span>,</span><br><span class="line">        batch=<span class="number">16</span>,</span><br><span class="line">        seed=<span class="number">42</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p>4）验证：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ultralytics <span class="keyword">import</span> YOLOv10</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># Load a custom model</span></span><br><span class="line">    model = YOLOv10(<span class="string">&#x27;runs/detect/train/weights/best.pt&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Validate the model，if test mode turn &quot;split=&#x27;test&#x27;&quot;</span></span><br><span class="line">    metrics = model.val(split=<span class="string">&#x27;val&#x27;</span>, save_json=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>5）测试：（用训练好的模型pt测试其他的数据）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ultralytics <span class="keyword">import</span> YOLOv10</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># Load a custom model</span></span><br><span class="line">    model = YOLOv10(<span class="string">&#x27;runs/detect/train/weights/best.pt&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Predict on an image</span></span><br><span class="line">    results = model.predict(source=<span class="string">&quot;ultralytics/assets&quot;</span>, device=<span class="string">&#x27;0&#x27;</span>, visualize=<span class="literal">True</span>, save=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Print results</span></span><br><span class="line">    <span class="built_in">print</span>(results)</span><br></pre></td></tr></table></figure><p>6）读取特征：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入所需的包</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np<span class="comment">#导入npy文件路径位置</span></span><br><span class="line">test = np.load(<span class="string">&#x27;runs/detect/predict/zidane/stage2_C2f_features.npy&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(test.shape[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><h2 id="三、代码地址"><a href="#三、代码地址" class="headerlink" title="三、代码地址"></a>三、代码地址</h2><p><a href="https://github.com/Lucki-ly/yolov10">https://github.com/Lucki-ly/yolov10</a></p><h2 id="四、效果展示"><a href="#四、效果展示" class="headerlink" title="四、效果展示"></a>四、效果展示</h2><h3 id="（1）训练结果："><a href="#（1）训练结果：" class="headerlink" title="（1）训练结果："></a>（1）训练结果：</h3><p><img src="/2024/07/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0%E5%92%8Cyolov10%E5%AE%9E%E7%8E%B0%E6%B0%B4%E4%B8%8B%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88RUOD%EF%BC%89/2.png" alt="2"></p><h3 id="（2）验证结果："><a href="#（2）验证结果：" class="headerlink" title="（2）验证结果："></a>（2）验证结果：</h3><p><img src="/2024/07/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0%E5%92%8Cyolov10%E5%AE%9E%E7%8E%B0%E6%B0%B4%E4%B8%8B%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88RUOD%EF%BC%89/3.png" alt="3"></p><h3 id="（3）测试结果："><a href="#（3）测试结果：" class="headerlink" title="（3）测试结果："></a>（3）测试结果：</h3><p><img src="/2024/07/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0%E5%92%8Cyolov10%E5%AE%9E%E7%8E%B0%E6%B0%B4%E4%B8%8B%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88RUOD%EF%BC%89/4.png" alt="4"></p><p><img src="/2024/07/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0%E5%92%8Cyolov10%E5%AE%9E%E7%8E%B0%E6%B0%B4%E4%B8%8B%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88RUOD%EF%BC%89/5.png" alt="5"></p><p><img src="/2024/07/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0%E5%92%8Cyolov10%E5%AE%9E%E7%8E%B0%E6%B0%B4%E4%B8%8B%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88RUOD%EF%BC%89/6.png" alt="6"></p><p><img src="/2024/07/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0%E5%92%8Cyolov10%E5%AE%9E%E7%8E%B0%E6%B0%B4%E4%B8%8B%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88RUOD%EF%BC%89/7.png" alt="7"></p><p><img src="/2024/07/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0%E5%92%8Cyolov10%E5%AE%9E%E7%8E%B0%E6%B0%B4%E4%B8%8B%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88RUOD%EF%BC%89/8.jpg" alt="8"></p><p><img src="/2024/07/25/%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%AE%9E%E4%BE%8B%E5%AD%A6%E4%B9%A0%E5%92%8Cyolov10%E5%AE%9E%E7%8E%B0%E6%B0%B4%E4%B8%8B%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88RUOD%EF%BC%89/9.jpg" alt="9"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch和torch_geometric安装（Windows）</title>
      <link href="/2024/07/25/Pytorch%E5%92%8Ctorch_geometric%E5%AE%89%E8%A3%85%EF%BC%88Windows%EF%BC%89/"/>
      <url>/2024/07/25/Pytorch%E5%92%8Ctorch_geometric%E5%AE%89%E8%A3%85%EF%BC%88Windows%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="一、引言和tips"><a href="#一、引言和tips" class="headerlink" title="一、引言和tips"></a>一、引言和tips</h2><p>记录一些经常用到的技巧和命令，可以快速部署环境，防止浪费生命！</p><h3 id="（1）pip安装python-库（清华源）"><a href="#（1）pip安装python-库（清华源）" class="headerlink" title="（1）pip安装python 库（清华源）"></a>（1）pip安装python 库（清华源）</h3><p>1）安装numpy（替换库）为例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><p>2）安装依赖文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><p>3）阿里源：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tb-nightly -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com</span><br></pre></td></tr></table></figure><h3 id="（2）查看电脑GPU显卡的版本"><a href="#（2）查看电脑GPU显卡的版本" class="headerlink" title="（2）查看电脑GPU显卡的版本"></a>（2）查看电脑GPU显卡的版本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Nvidia-smi</span><br></pre></td></tr></table></figure><p>可以直接看到自己的电脑cuda版本，方便后续安装pytorch。</p><h2 id="二、Anaconda虚拟环境命令（可选）"><a href="#二、Anaconda虚拟环境命令（可选）" class="headerlink" title="二、Anaconda虚拟环境命令（可选）"></a>二、Anaconda虚拟环境命令（可选）</h2><p>打开<code>anaconda prompt</code>命令行（有报错，权限不够，用管理员身份进入）</p><h3 id="（1）修改anaconda镜像源为国内（清华源）"><a href="#（1）修改anaconda镜像源为国内（清华源）" class="headerlink" title="（1）修改anaconda镜像源为国内（清华源）"></a>（1）修改anaconda镜像源为国内（清华源）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br></pre></td></tr></table></figure><h3 id="（2）虚拟环境命令"><a href="#（2）虚拟环境命令" class="headerlink" title="（2）虚拟环境命令"></a>（2）虚拟环境命令</h3><p>1）创建虚拟环境</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create --name myenv python=3.10</span><br></pre></td></tr></table></figure><p>2）进入虚拟环境</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate myenv</span><br></pre></td></tr></table></figure><p>3）退出虚拟环境</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda deactivate</span><br></pre></td></tr></table></figure><h2 id="三、Pytorch安装"><a href="#三、Pytorch安装" class="headerlink" title="三、Pytorch安装"></a>三、Pytorch安装</h2><h3 id="（1）打开官网地址"><a href="#（1）打开官网地址" class="headerlink" title="（1）打开官网地址"></a>（1）打开官网地址</h3><p><a href="https://pytorch.org/get-started/locally/">Start Locally | PyTorch</a></p><p>如下图所示，选择对应的系统（这里是Windows版本），用pip安装（conda比较慢）：</p><p><img src="/2024/07/25/Pytorch%E5%92%8Ctorch_geometric%E5%AE%89%E8%A3%85%EF%BC%88Windows%EF%BC%89/1.png" alt="1"></p><p>直接将命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121</span><br></pre></td></tr></table></figure><p>复制到<code>anaconda prompt</code>里（要进入你的虚拟环境里），等待安装完成。</p><h3 id="（2）查看pytorch版本"><a href="#（2）查看pytorch版本" class="headerlink" title="（2）查看pytorch版本"></a>（2）查看pytorch版本</h3><p>在虚拟环境中的<code>anaconda prompt</code>里输入以下命令，并回车</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python</span><br></pre></td></tr></table></figure><p>进入python后，可以知道自己的python版本，输入命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.__version__)                <span class="comment"># 查看pytorch安装的版本号</span></span><br><span class="line"><span class="built_in">print</span>(torch.cuda.is_available())        <span class="comment"># 查看cuda是否可用。True为可用，即是gpu版本pytorch</span></span><br><span class="line"><span class="built_in">print</span>(torch.cuda.get_device_name(<span class="number">0</span>))    <span class="comment"># 返回GPU型号</span></span><br><span class="line"><span class="built_in">print</span>(torch.cuda.device_count())        <span class="comment"># 返回可以用的cuda（GPU）数量，0代表一个</span></span><br><span class="line"><span class="built_in">print</span>(torch.version.cuda)               <span class="comment"># 查看cuda的版本</span></span><br></pre></td></tr></table></figure><h2 id="四、Torch-geometric安装"><a href="#四、Torch-geometric安装" class="headerlink" title="四、Torch_geometric安装"></a>四、Torch_geometric安装</h2><h3 id="（1）直接pip安装"><a href="#（1）直接pip安装" class="headerlink" title="（1）直接pip安装"></a>（1）直接pip安装</h3><p>在国内，如果直接输入以下命令，正常是安装失败的：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch_geometric</span><br></pre></td></tr></table></figure><p>解决方法也很简单，就是离线安装。</p><h3 id="（2）离线whl安装"><a href="#（2）离线whl安装" class="headerlink" title="（2）离线whl安装"></a>（2）离线whl安装</h3><p>1）先进入pyg的官网whl地址：<a href="https://data.pyg.org/whl/">data.pyg.org&#x2F;whl&#x2F;</a></p><p>2）根据我们自己的电脑系统版本、python版本、CPU（GPU）版本、torch版本下载对应的whl：</p><p>首先，根据torch版本、cpu&#x2F;cuda版本选择：<br><img src="/2024/07/25/Pytorch%E5%92%8Ctorch_geometric%E5%AE%89%E8%A3%85%EF%BC%88Windows%EF%BC%89/2.png" alt="2"></p><p>举个例子：这里的<code>torch-2.3.0+cu121</code>是说torch版本是2.3.0，cuda版本是12.1。</p><p>然后点击进去，</p><p>我们要下载四个whl（版本越新越好）：torch_cluster、torch_scatter、torch_sparse和torch_spline_conv。</p><p>然后根据你的电脑版本、python版本、cpu&#x2F;cuda版本选择：<br><img src="/2024/07/25/Pytorch%E5%92%8Ctorch_geometric%E5%AE%89%E8%A3%85%EF%BC%88Windows%EF%BC%89/3.png" alt="3"></p><p>举个例子：这里的<code>torch_scatter-2.1.2+pt23cu121-cp310-cp310-win_amd64.whl</code>是说torch_scatter版本是2.1.2，cuda版本是12.1，python版本是3.10系列的，电脑系统版本是Windows x64。</p><p>下载到你看得到的文件目录中。</p><p>3）安装whl文件和pyg库</p><p>回到<code>anaconda prompt</code>（虚拟环境中的）进入到下载的目录中，输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install xxx.whl -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><p>注意：不要修改文件名字，要原原本本。</p><p>最后再输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch_geometric -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><p>在<code>pip list</code>中可以看到安装后的pyg库。</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>YOLOv5和DeepSORT的智能交通流量监测系统</title>
      <link href="/2024/07/22/YOLOv5%E5%92%8CDeepSORT%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E6%B5%81%E9%87%8F%E7%9B%91%E6%B5%8B%E7%B3%BB%E7%BB%9F/"/>
      <url>/2024/07/22/YOLOv5%E5%92%8CDeepSORT%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E6%B5%81%E9%87%8F%E7%9B%91%E6%B5%8B%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h2 id="一、Yolov5的环境搭建"><a href="#一、Yolov5的环境搭建" class="headerlink" title="一、Yolov5的环境搭建"></a>一、Yolov5的环境搭建</h2><h2 id="（1）软硬件配置："><a href="#（1）软硬件配置：" class="headerlink" title="（1）软硬件配置："></a>（1）软硬件配置：</h2><p>1）软件配置：</p><p>python版本（3.9.7）+pytorch版本（2.0.0+cu117）+anaconda</p><p>2）硬件配置：Window 10（64位）+Nvidia Geforce 1080ti</p><h2 id="（2）需要安装的包："><a href="#（2）需要安装的包：" class="headerlink" title="（2）需要安装的包："></a>（2）需要安装的包：</h2><p>1）依赖库，用下面命令安装：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>2）opencv、torchreid等手动安装，直接<code>pip install xxx</code>即可。</p><h2 id="（3）问题和解决方法："><a href="#（3）问题和解决方法：" class="headerlink" title="（3）问题和解决方法："></a>（3）问题和解决方法：</h2><p>1）遇到报错“UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.”</p><p>解决方法：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install Cython</span><br></pre></td></tr></table></figure><p>2）遇到报错“AttributeError: module ‘numpy‘ has no attribute ‘float‘“</p><p>解决方法：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install 更低版本的numpy(最好是和python版本对应的)</span><br></pre></td></tr></table></figure><p>3）遇到报错no module named “torchreid”</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">不要pip install torchreid</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install https://github.com/KaiyangZhou/deep-person-reid/archive/master.zip</span><br></pre></td></tr></table></figure><p>遇到网络错误，就直接本地下载，然后<code>pip install</code>；</p><p>遇到C++报错，如下：</p><p><img src="/2024/07/22/YOLOv5%E5%92%8CDeepSORT%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E6%B5%81%E9%87%8F%E7%9B%91%E6%B5%8B%E7%B3%BB%E7%BB%9F/1.png" alt="1"></p><p>解决方法：<a href="https://visualstudio.microsoft.com/zh-hans/visual-cpp-build-tools/">Visual Studio 官网地址</a></p><p>勾选<code>使用C++的桌面开发</code>这个组件再运行上面的命令就解决了。</p><h2 id="二、代码介绍"><a href="#二、代码介绍" class="headerlink" title="二、代码介绍"></a>二、代码介绍</h2><p>代码地址：<a href="https://github.com/Lucki-ly/High-speed-video-detection">https://github.com/Lucki-ly/High-speed-video-detection</a></p><p>这里介绍修改的内容：（1）main.py；（2）webui.py</p><p>main和webui功能上差别不大，区别在于前者是做程序命令，运行完就没了；后者是一个UI界面，可以一直提交任务。</p><p>整个代码分为<code>detect</code>函数和一个主函数，我改的是<code>detect</code>函数。所以我把<code>detect</code>代码分为这三大块：</p><h3 id="1）初始化代码（包括deepsort模型、数据加载器、追踪器等）；"><a href="#1）初始化代码（包括deepsort模型、数据加载器、追踪器等）；" class="headerlink" title="1）初始化代码（包括deepsort模型、数据加载器、追踪器等）；"></a>1）初始化代码（包括deepsort模型、数据加载器、追踪器等）；</h3><h3 id="2）数据处理（预测、NMS非极大值抑制、检测结果后处理）；"><a href="#2）数据处理（预测、NMS非极大值抑制、检测结果后处理）；" class="headerlink" title="2）数据处理（预测、NMS非极大值抑制、检测结果后处理）；"></a>2）数据处理（预测、NMS非极大值抑制、检测结果后处理）；</h3><p>1、在代码的开头定义一个全局字典，用于存储识别结果和计数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">global</span> count_dict</span><br><span class="line">count_dict = &#123;&#125;</span><br></pre></td></tr></table></figure><p>2、对线宽进行增大，可视化更可观。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">annotator = Annotator(im0, line_width=<span class="number">10</span>, pil=<span class="keyword">not</span> <span class="built_in">ascii</span>)  <span class="comment">#标签处理</span></span><br></pre></td></tr></table></figure><h3 id="3）可视化"><a href="#3）可视化" class="headerlink" title="3）可视化"></a>3）可视化</h3><p><code>show_vid</code>显示视频参数、<code>save_vid</code>保存视频参数和打印结果，可视化改动比较大，也是主要的任务：</p><p>1、对于<code>show_vid</code>显示视频参数：</p><p>a）动态显示当前检测到的每种类别的数量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y_offset = <span class="number">120</span></span><br><span class="line"><span class="keyword">for</span> class_name, count <span class="keyword">in</span> count_dict.items():</span><br><span class="line">    cv2.putText(im0, <span class="string">f&#x27;<span class="subst">&#123;class_name&#125;</span>: <span class="subst">&#123;count&#125;</span>&#x27;</span>, (<span class="number">10</span>, y_offset), cv2.FONT_HERSHEY_SIMPLEX, <span class="number">6</span>, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">5</span>)</span><br><span class="line">    y_offset += <span class="number">200</span>  </span><br></pre></td></tr></table></figure><p>b）创建一个用于显示的缩放图像：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">display_scale_percent = <span class="number">25</span>  <span class="comment"># 调整显示窗口的缩放比例</span></span><br><span class="line">display_width = <span class="built_in">int</span>(im0.shape[<span class="number">1</span>] * display_scale_percent / <span class="number">100</span>)</span><br><span class="line">display_height = <span class="built_in">int</span>(im0.shape[<span class="number">0</span>] * display_scale_percent / <span class="number">100</span>)</span><br><span class="line">display_dim = (display_width, display_height)</span><br><span class="line">im0_display = cv2.resize(im0, display_dim, interpolation=cv2.INTER_AREA)</span><br><span class="line">            </span><br><span class="line">cv2.imshow(<span class="built_in">str</span>(p), im0_display)</span><br><span class="line">cv2.waitKey(<span class="number">1</span>)  <span class="comment"># 1 millisecond</span></span><br></pre></td></tr></table></figure><p>2、对于save_vid保存视频参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yield imres,im</span></span><br><span class="line"><span class="keyword">if</span> vid_path[i] != save_path:  <span class="comment"># new video</span></span><br><span class="line">vid_path[i] = save_path</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(vid_writer[i], cv2.VideoWriter):</span><br><span class="line">vid_writer[i].release()  <span class="comment"># release previous video writer</span></span><br><span class="line"><span class="keyword">if</span> vid_cap:  <span class="comment"># video</span></span><br><span class="line">fps = vid_cap.get(cv2.CAP_PROP_FPS)</span><br><span class="line">w = <span class="built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))</span><br><span class="line">h = <span class="built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))</span><br><span class="line"><span class="keyword">else</span>:  <span class="comment"># stream</span></span><br><span class="line">fps, w, h = <span class="number">30</span>, im0.shape[<span class="number">1</span>], im0.shape[<span class="number">0</span>]</span><br><span class="line">save_path = <span class="built_in">str</span>(Path(save_path).with_suffix(<span class="string">&#x27;.mp4&#x27;</span>))  <span class="comment"># force *.mp4 suffix on results videos</span></span><br><span class="line">vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*<span class="string">&#x27;mp4v&#x27;</span>), fps, (w, h))</span><br><span class="line">vid_writer[i].write(im0)</span><br></pre></td></tr></table></figure><p>3、删掉了Count_obj函数。</p><h2 id="三、运行方法"><a href="#三、运行方法" class="headerlink" title="三、运行方法"></a>三、运行方法</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd xxx\Vedio\code\VehicleCountor</span><br><span class="line">python main.py --save-vid --output \xxx\xxx\1\Vedio\code\VehicleCountor\inference\output</span><br></pre></td></tr></table></figure><h2 id="四、项目结果"><a href="#四、项目结果" class="headerlink" title="四、项目结果"></a>四、项目结果</h2><p><img src="/2024/07/22/YOLOv5%E5%92%8CDeepSORT%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E6%B5%81%E9%87%8F%E7%9B%91%E6%B5%8B%E7%B3%BB%E7%BB%9F/2.jpg" alt="2"></p><p><img src="/2024/07/22/YOLOv5%E5%92%8CDeepSORT%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E6%B5%81%E9%87%8F%E7%9B%91%E6%B5%8B%E7%B3%BB%E7%BB%9F/3.jpg" alt="3"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hexo个人博客搭建（Windows）</title>
      <link href="/2024/07/21/Hexo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%EF%BC%88Windows%EF%BC%89/"/>
      <url>/2024/07/21/Hexo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%EF%BC%88Windows%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="一、git工具安装"><a href="#一、git工具安装" class="headerlink" title="一、git工具安装"></a>一、git工具安装</h2><p>官网：<a href="https://git-scm.com/">https://git-scm.com/</a></p><p>安装后鼠标右键可以看到就是安装成功了。</p><p><img src="/2024/07/21/Hexo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%EF%BC%88Windows%EF%BC%89/1.png" alt="1"></p><h2 id="二、node-js安装"><a href="#二、node-js安装" class="headerlink" title="二、node.js安装"></a>二、node.js安装</h2><p>官网：<a href="https://nodejs.org/zh-cn">https://nodejs.org/zh-cn</a><br>安装后，鼠标右键选择<code>Open Git Bash here</code>：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node -v                                                     #查看node版本</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm -v                                                       #查看npm版本</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g cnpm --registry=http://registry.npm.taobao.org   #安装cnpm</span><br></pre></td></tr></table></figure><p>遇到的问题：<code>npm</code>安装时一直idealTree:npm: sill idealTree buildDeps<br>解决方法：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm config set registry https://registry.npmmirror.com</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm config get registry                                   #查看是否安装成功</span><br></pre></td></tr></table></figure><p>然后接着：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cnpm install -g hexo-cli                                    #安装hexo框架 </span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo -v                                                     #查看hexo版本</span><br></pre></td></tr></table></figure><h2 id="三、hexo配置和初始化"><a href="#三、hexo配置和初始化" class="headerlink" title="三、hexo配置和初始化"></a>三、hexo配置和初始化</h2><p>然后创建<code>blog</code>目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd blog                                                     #进入blog目录</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init                                              #生成博客 初始化博客</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s                                                    #启动本地博客服务</span><br></pre></td></tr></table></figure><p>本地访问地址：<code>http://localhost:4000/</code> ，不能访问就输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s -p 4001</span><br></pre></td></tr></table></figure><p>地址就变成：<code>http://localhost:4001/</code>，<code>Crtl+C</code>退出。</p><p>这里</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo n &quot;我的第一篇文章&quot;                                        #创建新的文章</span><br></pre></td></tr></table></figure><h2 id="四、Github设置"><a href="#四、Github设置" class="headerlink" title="四、Github设置"></a>四、Github设置</h2><p>在我们的github主页新建一个仓库，名字一定要是：<code>YourGithubName.github.io</code></p><p>然后在<code>blog</code>目录中找到<code>_config.yml</code>文件，打开它，在最后的部分修改：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Deployment</span></span><br><span class="line"><span class="comment">## Docs: https://hexo.io/docs/deployment.html</span></span><br><span class="line">  <span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">https://github.com/YourGithubName/YourGithubName.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">main</span></span><br></pre></td></tr></table></figure><p>（注意缩进两格和冒号后面一格）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d                                                 #部署到Github仓库里</span><br></pre></td></tr></table></figure><p>访问这个地址可以查看博客：<code>https://YourGithubName.github.io/</code></p><p>主题美化：（以yilia为主题）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia</span><br></pre></td></tr></table></figure><p>修改hexo根目录下的‘ <code>_config.yml</code>’ 文件 ： <code>theme: yilia</code></p><h2 id="五、遇到的问题"><a href="#五、遇到的问题" class="headerlink" title="五、遇到的问题"></a>五、遇到的问题</h2><h3 id="（1）hexo博客中插入图片失败"><a href="#（1）hexo博客中插入图片失败" class="headerlink" title="（1）hexo博客中插入图片失败"></a>（1）hexo博客中插入图片失败</h3><p>1、将<code>_config.yml</code> 文件中的<code>post_asset_folder</code> 选项设为 <code>true</code> 来打开。</p><p>2、typora（Markdown编辑器）图像设置：<a href="https://blog.csdn.net/m0_43401436/article/details/107191688">hexo博客中插入图片失败——解决思路及个人最终解决办法_hexo 文章插入图片失败-CSDN博客</a></p><p>3、插件下载：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install https://github.com/CodeFalling/hexo-asset-image --save</span><br></pre></td></tr></table></figure><p>4、注意格式：去掉前面的路径</p><p><img src="/2024/07/21/Hexo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%EF%BC%88Windows%EF%BC%89/2.png" alt="2"></p><h3 id="（2）github上传问题"><a href="#（2）github上传问题" class="headerlink" title="（2）github上传问题"></a>（2）github上传问题</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git init</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m &quot;1&quot;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -M main</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote add origin xxxx.git</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure><p>如果不行，就强制上传：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push -u origin main -f</span><br></pre></td></tr></table></figure><p>问题：文件太大传不上去，报错</p><p>解决方法：缩小文件夹，然后删掉<code>.github</code>和<code>.git</code>文件重新上传就可以了。</p>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Comfyui+Docker+Ollama+OpenwebUI笔记</title>
      <link href="/2024/07/19/Comfyui-Docker-Ollama-OpenwebUI%E7%AC%94%E8%AE%B0/"/>
      <url>/2024/07/19/Comfyui-Docker-Ollama-OpenwebUI%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="一、Docker（windows版本）"><a href="#一、Docker（windows版本）" class="headerlink" title="一、Docker（windows版本）"></a>一、Docker（windows版本）</h2><p>官网：<a href="https://www.docker.com/">Docker: Accelerated Container Application Development</a></p><h2 id="二、Ollama（Llama3为例子）"><a href="#二、Ollama（Llama3为例子）" class="headerlink" title="二、Ollama（Llama3为例子）"></a>二、Ollama（Llama3为例子）</h2><p>官网：<a href="https://ollama.com/">Ollama</a></p><h2 id="三、OpenwebUI"><a href="#三、OpenwebUI" class="headerlink" title="三、OpenwebUI"></a>三、OpenwebUI</h2><h3 id="（1）Github地址："><a href="#（1）Github地址：" class="headerlink" title="（1）Github地址："></a>（1）Github地址：</h3><p><a href="https://github.com/open-webui/open-webui">open-webui&#x2F;open-webui</a></p><h3 id="（2）确保-Ollama-在计算机上"><a href="#（2）确保-Ollama-在计算机上" class="headerlink" title="（2）确保 Ollama 在计算机上"></a>（2）<strong>确保 Ollama 在计算机上</strong></h3><p>请使用以下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main</span><br></pre></td></tr></table></figure><h3 id="（3）访问本地的OpenWebUI"><a href="#（3）访问本地的OpenWebUI" class="headerlink" title="（3）访问本地的OpenWebUI"></a>（3）访问本地的OpenWebUI</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:3000/</span><br></pre></td></tr></table></figure><p><img src="/2024/07/19/Comfyui-Docker-Ollama-OpenwebUI%E7%AC%94%E8%AE%B0/1.png" alt="1"></p><h2 id="四、Comfyui"><a href="#四、Comfyui" class="headerlink" title="四、Comfyui"></a>四、Comfyui</h2><h3 id="（1）参考教程："><a href="#（1）参考教程：" class="headerlink" title="（1）参考教程："></a>（1）参考教程：</h3><p><a href="https://www.bilibili.com/video/BV1Bi421e73X/?p=3&vd_source=0c4d2c8d0a9190a4bb7587a15f6341f2">2024最新的ConfyUI节点工作流详解</a></p><h3 id="（2）详细理解"><a href="#（2）详细理解" class="headerlink" title="（2）详细理解"></a>（2）详细理解</h3><p>（SD有个webui其实和Comfyui是异曲同工的效果，后者更专注于工作流的形式去完成工作。）</p><p>ComfyUI 是一个为Stable Diffusion专门设计的基于节点的图形用户界面（GUI）。它使用户能够通过链接不同的块（称为节点）来构建复杂的图像生成工作流程。这些节点可以包括各种任务，如加载检查点模型、输入提示、指定采样器等。</p><p>它实际上就是一个比较专业的 Stable Diffusion 运行界面，只不过是节点式的。这种节点式界面其实广泛的存在于各种专业的生产力工具中，例如 Blender、虚幻引擎、达芬奇等。</p><p><img src="/2024/07/19/Comfyui-Docker-Ollama-OpenwebUI%E7%AC%94%E8%AE%B0/2.jpg" alt="2"></p><h4 id="1、安装"><a href="#1、安装" class="headerlink" title="1、安装"></a>1、安装</h4><p>1）官方安装：Github地址：<a href="https://github.com/comfyanonymous/ComfyUI/releases">Releases · comfyanonymous&#x2F;ComfyUI (github.com)</a></p><p><img src="/2024/07/19/Comfyui-Docker-Ollama-OpenwebUI%E7%AC%94%E8%AE%B0/3.png" alt="3"></p><p>我们在完成安装包下载后，就可以直接运行 ComfyUI 了，双击<code>run_nvidia_gpu.bat</code>即可启动。</p><p>2）启动器一键安装：（B站秋叶整合包：<a href="https://www.bilibili.com/video/BV1Ew411776J/?spm_id_from=333.337.search-card.all.click">【AI绘画】ComfyUI整合包发布！解压即用 一键启动 工作流版界面 超多节点 ☆更新 ☆汉化 秋叶整合包_哔哩哔哩_bilibili</a>）</p><p>2、模型安装（<code>\ComfyUI_windows_portable\ComfyUI\models</code>）</p><p>推荐模型网站：1）<a href="https://civitai.com/models">Civitai Models | Discover Free Stable Diffusion Models</a>；2）<a href="https://huggingface.co/models">Models - Hugging Face</a>.</p><p>把下载的模型放到对应的模型类型的目录下即可。</p><p><img src="/2024/07/19/Comfyui-Docker-Ollama-OpenwebUI%E7%AC%94%E8%AE%B0/4.png" alt="4"></p><h4 id="3、共享模型配置参考以上视频"><a href="#3、共享模型配置参考以上视频" class="headerlink" title="3、共享模型配置参考以上视频"></a>3、共享模型配置参考以上视频</h4><h4 id="4、自定义节点设置"><a href="#4、自定义节点设置" class="headerlink" title="4、自定义节点设置"></a>4、自定义节点设置</h4><p>（自定义节点文件都是放在 ComfyUI 的「custom_nodes」目录中）</p><p>1）在线安装在<code>custom_nodes</code>目录下用<code>git clone</code>即可；</p><p>2）<a href="https://github.com/ltdrdata/ComfyUI-Manager">https://github.com/ltdrdata/ComfyUI-Manager</a> 直接本地下载仓库；</p><p>3）启动器安装.</p><h4 id="5、汉化节点安装通过“节点管理器「ComfyUI-Manager」”搜索“translate”来安装，记得用bat重启一次进行更新库。"><a href="#5、汉化节点安装通过“节点管理器「ComfyUI-Manager」”搜索“translate”来安装，记得用bat重启一次进行更新库。" class="headerlink" title="5、汉化节点安装通过“节点管理器「ComfyUI Manager」”搜索“translate”来安装，记得用bat重启一次进行更新库。"></a>5、<strong>汉化节点安装</strong>通过“节点管理器「ComfyUI Manager」”搜索“translate”来安装，记得用bat重启一次进行更新库。</h4><h4 id="6、剩下操作就是ComfyUI-Manager和一些节点、加载器做的文生图、视频多模态的工作流任务了。"><a href="#6、剩下操作就是ComfyUI-Manager和一些节点、加载器做的文生图、视频多模态的工作流任务了。" class="headerlink" title="6、剩下操作就是ComfyUI Manager和一些节点、加载器做的文生图、视频多模态的工作流任务了。"></a>6、剩下操作就是ComfyUI Manager和一些节点、加载器做的文生图、视频多模态的工作流任务了。</h4><h2 id="五、配置OpenwebUI"><a href="#五、配置OpenwebUI" class="headerlink" title="五、配置OpenwebUI"></a>五、配置OpenwebUI</h2><h3 id="（1）Ollama-API"><a href="#（1）Ollama-API" class="headerlink" title="（1）Ollama API"></a>（1）<strong>Ollama API</strong></h3><p><img src="/2024/07/19/Comfyui-Docker-Ollama-OpenwebUI%E7%AC%94%E8%AE%B0/5.png" alt="5"></p><h3 id="（2）关联ComfyUI"><a href="#（2）关联ComfyUI" class="headerlink" title="（2）关联ComfyUI"></a>（2）<strong>关联ComfyUI</strong></h3><p><img src="/2024/07/19/Comfyui-Docker-Ollama-OpenwebUI%E7%AC%94%E8%AE%B0/6.png" alt="6"></p><h3 id="（3）Llama-Comfyui绘制图"><a href="#（3）Llama-Comfyui绘制图" class="headerlink" title="（3）Llama+Comfyui绘制图"></a>（3）Llama+Comfyui绘制图</h3><p><img src="/2024/07/19/Comfyui-Docker-Ollama-OpenwebUI%E7%AC%94%E8%AE%B0/7.png" alt="7"></p>]]></content>
      
      
      <categories>
          
          <category> LLM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>ROS小车的安装---华为杯</title>
      <link href="/2024/07/19/ROS%E5%B0%8F%E8%BD%A6%E7%9A%84%E5%AE%89%E8%A3%85-%E5%8D%8E%E4%B8%BA%E6%9D%AF/"/>
      <url>/2024/07/19/ROS%E5%B0%8F%E8%BD%A6%E7%9A%84%E5%AE%89%E8%A3%85-%E5%8D%8E%E4%B8%BA%E6%9D%AF/</url>
      
        <content type="html"><![CDATA[<p>前提提要：测试软件采用minibalance（安卓）、wheeltec（IOS）;蓝牙连接上ROS-STM32，密码是1452.</p><h1 id="一、Ubuntu系统"><a href="#一、Ubuntu系统" class="headerlink" title="一、Ubuntu系统"></a><em>一、Ubuntu系统</em></h1><h2 id="1-双系统安装："><a href="#1-双系统安装：" class="headerlink" title="1. 双系统安装："></a>1. 双系统安装：</h2><p>参考教程：<a href="https://www.bilibili.com/video/BV1554y1n7zv/?spm_id_from=333.999.0.0&vd_source=0c4d2c8d0a9190a4bb7587a15f6341f2"><em>Windows 和 Ubuntu 双系统的安装和卸载</em></a>。</p><p>基本按照教程走，里面用U盘当成启动盘用到的工具采用rufus，使用方法参考视频： <a href="https://www.bilibili.com/video/BV1BP411577g/?vd_source=0c4d2c8d0a9190a4bb7587a15f6341f2">win11下用rufus安装Ubuntu双系统</a>。</p><p>需要注意的是：</p><p>1）Ubuntu这里选择20.04版本，内存至少要60GB；</p><p>2）台式机电脑进入Bios开发者模式（华硕是按F12），需要考虑USB启动（需要插上U盘），没有wifi使用接入网线或者手机数据线连接热点；</p><p>3）rufus工具里选择的文件系统FAT32（方便做介质，拓展性强）。</p><h2 id="2-安装显卡："><a href="#2-安装显卡：" class="headerlink" title="2. 安装显卡："></a>2. 安装显卡：</h2><p>（1）参考教程：<a href="https://www.bilibili.com/video/BV1wY411p7mU/?spm_id_from=333.337.search-card.all.click&vd_source=0c4d2c8d0a9190a4bb7587a15f6341f2"><em>NVIDIA显卡的Ubuntu驱动程序安装方法</em></a>。</p><p>（2）如果出现报错“ERROR: The Nouveau kernel driver is currently in use by your system. This driver is incompatible with the NVIDIA driver。”表示Ubuntu自带的驱动与需要安装的显卡驱动发生冲突，需要禁用。</p><p>1）将<code>nouveau</code>驱动加入黑名单，将以下内容加入<code>/etc/modprobe.d/blacklist.conf</code>文件中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim（gedit也可以） /etc/modprobe.d/blacklist.conf</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">blacklist vga16fb</span><br><span class="line">blacklist nouveau</span><br><span class="line">blacklist rivafb</span><br><span class="line">blacklist rivatv</span><br><span class="line">blacklist nvidiafb</span><br></pre></td></tr></table></figure><p>2）然后执行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo update-initramfs -u</span><br></pre></td></tr></table></figure><p>重启电脑，执行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lsmod | grep nouveau</span><br></pre></td></tr></table></figure><p>如果没有输出就证明禁用成功<br>3）然后安装显卡驱动：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod a+x xxx.run</span><br><span class="line">sudo ./xxx.run -no-x-check -no-nouveau-check -no-opengl-files</span><br></pre></td></tr></table></figure><p>注意：如果缺少g++，gcc，make等依赖报错，执行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install xxx</span><br></pre></td></tr></table></figure><p>4）安装验证，输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure><p>安装后得到的显卡（我们这里是NVIDIA GTX1080Ti）结果如下：</p><p><img src="/2024/07/19/ROS%E5%B0%8F%E8%BD%A6%E7%9A%84%E5%AE%89%E8%A3%85-%E5%8D%8E%E4%B8%BA%E6%9D%AF/1.JPG" alt="1"></p><h1 id="二、ROS系统"><a href="#二、ROS系统" class="headerlink" title="二、ROS系统"></a><em>二、ROS系统</em></h1><h2 id="1、学习教程："><a href="#1、学习教程：" class="headerlink" title="1、学习教程："></a>1、学习教程：</h2><p><a href="https://www.bilibili.com/video/BV1BP4y1o7pw/?spm_id_from=333.999.0.0&vd_source=0c4d2c8d0a9190a4bb7587a15f6341f2">机器人操作系统 ROS 快速入门教程</a>。</p><p><img src="/2024/07/19/ROS%E5%B0%8F%E8%BD%A6%E7%9A%84%E5%AE%89%E8%A3%85-%E5%8D%8E%E4%B8%BA%E6%9D%AF/2.png" alt="2"></p><p>现在主要是两个机器人系统ROS1和ROS2，每个系统对应的软件操作系统都有不同的版本，两个机器人系统的区别在于ROS1仅支持linux操作系统；而ROS2可以支持windows、linux和macos系统。</p><p>我们以ROS1系统为例子。这里采用的是Ubuntu20.04，所以对应的ROS版本为noetic，具体如下图：</p><p> <img src="/2024/07/19/ROS%E5%B0%8F%E8%BD%A6%E7%9A%84%E5%AE%89%E8%A3%85-%E5%8D%8E%E4%B8%BA%E6%9D%AF/3.png" alt="3"></p><h2 id="2、环境部署与安装"><a href="#2、环境部署与安装" class="headerlink" title="2、环境部署与安装"></a>2、环境部署与安装</h2><p>（1）这里我们使用fishros（鱼香）的github项目一键安装ros系统。地址：<a href>https://github.com/fishros/install</a>；</p><p>（2）安装完后可以<code>roscore</code>一下，然后在<code>catkin_ws</code>目录下进<code>catkin_make</code>，如果出现报错，就运行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install ros-neotic-缺少库名</span><br></pre></td></tr></table></figure><p>（其他报错问题请转第三点）；</p><p>（3）这里注意一点，我们每次<code>roscore</code>之后，需要做一个额外的操作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source devel/setup.bash</span><br></pre></td></tr></table></figure><p>（这里最好是绝对路径）；</p><p>（4）当我们catkin_make通过以后（可以用小乌龟去验证一下，这里不详细介绍），我们可以选择真实机器人去跑代码（记得连接蓝牙）或者仿真软件去模拟robot，但我们这里采用主从机的分配方式来减少算力运行压力。因此我们这里需要做一个主从机的通信，主机承担人工智能算法的算力（GPU）运算，从机承担简单的控制驱动的执行。参考：<a href="https://blog.csdn.net/zhanghm1995/article/details/106781954">一遍成功的ROS主从机详细配置_一遍成功ros-CSDN博客</a>。</p><p>此项目的主从机IP设置如下：</p><p>台式机电脑作为主机</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">ROS主机的bashrc文件</span></span><br><span class="line">sudo gedit(或者vim) ~/.bashrc</span><br><span class="line">export ROS_MASTER_URI=http://10.70.26.59:11311</span><br><span class="line">export ROS_HOSTNAME=10.70.26.59</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><p>STM32开发板作为从机</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">ROS从机的bashrc文件</span></span><br><span class="line">sudo gedit(或者vim) ~/.bashrc</span><br><span class="line">export ROS_MASTER_URI=http://10.70.26.59:11311</span><br><span class="line">export ROS_HOSTNAME=10.31.216.89</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><p>这里记得按照教程去<code>/etc/hosts</code>里面填写主从机IP地址，以下是主机电脑ssh远程连接从机的实例：</p><p><img src="/2024/07/19/ROS%E5%B0%8F%E8%BD%A6%E7%9A%84%E5%AE%89%E8%A3%85-%E5%8D%8E%E4%B8%BA%E6%9D%AF/4.JPG" alt="4"></p><h2 id="3、遇到的问题及其解决方法"><a href="#3、遇到的问题及其解决方法" class="headerlink" title="3、遇到的问题及其解决方法"></a>3、遇到的问题及其解决方法</h2><p>（1）PermissionError:[Errno 13] Permission dented:’&#x2F;tmp&#x2F;fish_install.yaml’</p><p>解决方法：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo+命令</span><br></pre></td></tr></table></figure><p>（2）编译catkin时遇到错误</p><p>解决方法：<a href="https://blog.csdn.net/qq_42910179/article/details/106881279">ROS学习笔记（四）：编译catkin时遇到的错误经历</a></p><p>（3）-bash: .&#x2F;restart.sh: &#x2F;bin&#x2F;sh^M: 坏的解释器: 没有那个文件或目录</p><p>解决方法：<a href="https://blog.csdn.net/weixin_44310241/article/details/126428617?ops_request_misc=%7B%22request_id%22:%22171998509716800227481633%22,%22scm%22:%2220140713.130102334.pc_all.%22%7D&request_id=171998509716800227481633&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-126428617-null-null.142%5Ev100%5Epc_search_result_base5&utm_term=./sh%E6%89%BE%E4%B8%8D%E5%88%B0%E8%A7%A3%E9%87%8A%E5%99%A8&spm=1018.2226.3001.4187">-bash: .&#x2F;restart.sh: &#x2F;bin&#x2F;sh^M: 坏的解释器: 没有那个文件或目录_</a></p><p>（4）[rospack] Error: package ‘pub_pkg‘ not found</p><p>解决方法：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source devel/setup.bash</span><br></pre></td></tr></table></figure><p>（5）&#x2F;usr&#x2F;bin&#x2F;env: “python3\r”: 没有那个文件或目录</p><p>解决方法：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install dos2unix</span><br><span class="line"></span><br><span class="line">dos2unix &lt;filename&gt;</span><br></pre></td></tr></table></figure><p>（6）关于ros版本的库被遗弃或者不存在的情况（这里以<code>orocos-bfl</code>为例子）</p><p>解决方法：首先想好把库放入的文件目录位置（一般是src）</p><p>1、下载github网址的仓库；</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd src</span><br><span class="line">git clone https://github.com/jyLeo/orocos-bfl.git</span><br></pre></td></tr></table></figure><p>2、创建build文件夹；</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd src/orocos-bfl</span><br><span class="line">mkdir build</span><br><span class="line">cd build</span><br></pre></td></tr></table></figure><p>3、编译安装。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cmake -DCMAK_BUILD_TYPE=Release ..</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure><p>（7）<code>catkin_ws</code>目录下的<code>installed_packged</code>文件夹运行<code>install_packages.sh</code>脚本文件出现<code>无法定位软件包</code>问题</p><p>解决方法：对<code>install_packages.sh</code>内容替换：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义日志文件路径</span></span><br><span class="line">LOG_FILE=<span class="string">&quot;installation.log&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 清空日志文件，准备记录新的日志</span></span><br><span class="line">&gt; <span class="string">&quot;<span class="variable">$LOG_FILE</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查APT更新是否成功</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;开始更新软件包列表...&quot;</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get update &amp;&gt;&gt; <span class="string">&quot;<span class="variable">$LOG_FILE</span>&quot;</span></span><br><span class="line"><span class="keyword">if</span> [ $? -ne 0 ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;APT更新失败，请检查网络连接或软件源配置。&quot;</span> | <span class="built_in">tee</span> -a <span class="string">&quot;<span class="variable">$LOG_FILE</span>&quot;</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取包含软件包名称的文件</span></span><br><span class="line">PACKAGE_LIST=<span class="string">&quot;installed_packages1.txt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查包列表文件是否存在</span></span><br><span class="line"><span class="keyword">if</span> [ ! -f <span class="string">&quot;<span class="variable">$PACKAGE_LIST</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;包列表文件 <span class="variable">$PACKAGE_LIST</span> 不存在。&quot;</span> | <span class="built_in">tee</span> -a <span class="string">&quot;<span class="variable">$LOG_FILE</span>&quot;</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取文件并尝试安装每个软件包</span></span><br><span class="line"><span class="keyword">while</span> IFS= <span class="built_in">read</span> -r package_name; <span class="keyword">do</span></span><br><span class="line">    <span class="comment"># 清理包名中的不可见字符和多余空格</span></span><br><span class="line">    cleaned_package_name=$(<span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$package_name</span>&quot;</span> | <span class="built_in">tr</span> -d <span class="string">&#x27;[:space:]&#x27;</span> | <span class="built_in">tr</span> -d <span class="string">&#x27;\r\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;正在安装软件包: <span class="variable">$cleaned_package_name</span>&quot;</span> | <span class="built_in">tee</span> -a <span class="string">&quot;<span class="variable">$LOG_FILE</span>&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 执行安装命令</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;执行命令: sudo apt-get install <span class="variable">$cleaned_package_name</span> -y&quot;</span> | <span class="built_in">tee</span> -a <span class="string">&quot;<span class="variable">$LOG_FILE</span>&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">sudo</span> apt-get install <span class="string">&quot;<span class="variable">$cleaned_package_name</span>&quot;</span> -y &amp;&gt;&gt; <span class="string">&quot;<span class="variable">$LOG_FILE</span>&quot;</span>; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;软件包 <span class="variable">$cleaned_package_name</span> 安装成功!&quot;</span> | <span class="built_in">tee</span> -a <span class="string">&quot;<span class="variable">$LOG_FILE</span>&quot;</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;软件包 <span class="variable">$cleaned_package_name</span> 安装失败，尝试修复依赖...&quot;</span> | <span class="built_in">tee</span> -a <span class="string">&quot;<span class="variable">$LOG_FILE</span>&quot;</span></span><br><span class="line">        <span class="comment"># 尝试修复依赖问题</span></span><br><span class="line">        <span class="built_in">sudo</span> apt-get -f install &amp;&gt;&gt; <span class="string">&quot;<span class="variable">$LOG_FILE</span>&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">sudo</span> apt-get install <span class="string">&quot;<span class="variable">$cleaned_package_name</span>&quot;</span> -y &amp;&gt;&gt; <span class="string">&quot;<span class="variable">$LOG_FILE</span>&quot;</span>; <span class="keyword">then</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;软件包 <span class="variable">$cleaned_package_name</span> 修复依赖后安装成功。&quot;</span> | <span class="built_in">tee</span> -a <span class="string">&quot;<span class="variable">$LOG_FILE</span>&quot;</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;软件包 <span class="variable">$cleaned_package_name</span> 修复依赖后仍安装失败。&quot;</span> | <span class="built_in">tee</span> -a <span class="string">&quot;<span class="variable">$LOG_FILE</span>&quot;</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span> &lt; <span class="string">&quot;<span class="variable">$PACKAGE_LIST</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;脚本运行结束。&quot;</span> | <span class="built_in">tee</span> -a <span class="string">&quot;<span class="variable">$LOG_FILE</span>&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="4、摄像头安装（intel）"><a href="#4、摄像头安装（intel）" class="headerlink" title="4、摄像头安装（intel）"></a>4、摄像头安装（intel）</h2>]]></content>
      
      
      <categories>
          
          <category> Robot </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
